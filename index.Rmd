---
title: "Analysis of Weight Lifting Exercise dataset"
author: "Foo HP"
date: "Thursday, December 24, 2015"
output: 
    html_document:
      keep_md: TRUE
---
## Synopsis
 
The objective of this project is to use data from <http://groupware.les.inf.puc-rio.br/har> (see the section on the Weight Lifting Exercise Dataset) to investigate "how (well)" an activity was performed by the wearer.

6 participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).


The goal is to predict the manner in which they did the exercise( "classe" variable )  using any of the other variables to predict with. i.e. predict activity quality from activity monitors/sensors


## Data
 
The data for this project come from the source:

<http://groupware.les.inf.puc-rio.br/har>


The training data for this project : 

<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>

The test data for this project : 

<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>



## Load Data and required packages
```{r,warning=FALSE,message=FALSE}
library(caret)
library(rpart)
library(randomForest)

trainU <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"  
testU<- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
Org_Training <- read.csv(url(trainU),na.strings=c("NA",""))
Org_Test <- read.csv(url(testU),na.strings=c("NA",""))
```

## Process and Clean the Data
The original training and test datasets  provided for this project, contain (19622 observations of 160 variables) and  (20 observations of 160 variables) respectively.
Both datasets contain the same variables except for the last variable, the orignal training dataset contain the outcome variable "classe" whereas the original test dataset contain the variable "problem_id".

Out of the 160 variables, 152 variables are measurements related to the 4 sensors (arm,forearm,belt & dumbbell).  On exploration of the Original Training data, I discovered that there are many missing values or NAs. 60 variables contain zero NAs and the remaining 100 variables contain 97.93 % NAs. As the 100 variables contain a significant percentage (97.93%) of NAs and may not be good predictors,these variables will be removed. 

The first 7 column variables of the Original Training dataset, 

X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,new_window,num_window

relate to the identity of the participant, the timestamp and sliding window .

These are **NON-sensor** related variables and as such are not relevant predictors for the outcome, and will be removed.  

The trimmed training dataset (Trim_Training) now contains 52 predictor variables and 1 outcome variable.

Next, check for near zero variance predictors from the remaining 52 predictor variables  and conclude that there are **NO** zero variance predictors within them.

Similarly, the trimmed Test dataset(Trim_Test) also contain 52 predictor variables.


## Cross Validation & Out of sample error

Split the Trim_Training dataset into training (60%) and testing (40%) datasets using 
createDataPartition. Build a model on the training subset and evaluate on the testing subset (held out).

Out of sample error is the error resulted from applying the prediction algorithm to a new data set. I expect the out of sample error to be small.  To accurately estimate the out of sample error ,it is important to hold out an untouched sample (e.g. testing subset). Using ConfusionMatrix, the estimated out of sample error is computed as (1- accuracy). 

## Build Model - Classification Tree
Fit classification tree as a model on the training subset. Plot the classification Tree. Predict on the testing subset and tabulate the predictions of the model against the actual outcome using ConfusionMatrix. The accuracy of this model (Fit1) is 0.5654 The estimated out of sample error is (1- accuracy) =  **0.4346**

## Build Model - Random Forest
Fit model on the training subset using randomForest algorithm .Plot Dotchart of variable importance as measured by Random Forest.Predict on the testing subset and tabulate the predictions of the model against the actual outcome using ConfusionMatrix. The accuracy of this model (Fit2) is 0.9918  The estimated out of sample error is (1- accuracy) = **0.0082** 

## Conclusion 
The model Fit 2 ,built using randomForest algorithm is a better model (0.9918) compared to Classification Tree (0.5654) in terms of higher accuracy and lower out of sample error 
(0.0082) compared to (0.4346). As such this model will be  used to predict the 20 different test cases . 
The prediction result is :

  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B  

## Reference

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.



\newpage

# Appendix   

```{r}
dim(Org_Training)
dim(Org_Test)
```

```{r}
Nomatch <- !(names(Org_Training) %in% names(Org_Test))
nameTr <- names(Org_Training)     # Variable names of Original Training dataset
sensordata_var <- nameTr[grepl("_arm|_forearm|_belt|_dumbbell",nameTr)]
length(sensordata_var)            #number of sensor related variables
nameTr[Nomatch]                   # Non-match variable in Original Training dataset
nameTs <- names(Org_Test)         # Variable names of Original Test dataset
nameTs[Nomatch]                   # Non-match variable in Original Test dataset
a <-sapply(Org_Training,is.na)     ## Check for NAs
b <-colSums(a)               ## Identify number of NAs in column 
c <- round(b*100/nrow(Org_Training),2)  ## Percentage of NAs in column
table(c)                     ## Tabulate percentage of NAs 

Trim_Training <- Org_Training[which(b==0)] ## Extract zero NA columns 
## Further trim out the non-relevant variables
Trim_Training <- Trim_Training[,-c(1:7)]
 ##Extract similar variables for Test data set except "classe" column (col 53)
Trim_Test <- Org_Test[colnames(Trim_Training[,-53])] 
# Check for near zero variance on the 52 variables excluding "classe" variable 
NZV <- nearZeroVar(Trim_Training[,-53],saveMetrics=TRUE)
# Identify whether any near zero variance predictors exist in Trim_Training
near_zero_item <- sum(NZV$nzv)
near_zero_item
```

# Cross Validation
```{r}
set.seed(3388)
inTrain<-createDataPartition(y=Trim_Training$classe, p=0.6, list=FALSE)
training <-Trim_Training[inTrain, ]
testing <-Trim_Training[-inTrain, ]
dim(training)
dim(testing)


```
Build Model - Classification Tree
```{r}
Fit1 <- train(classe~ .,data=training,method="rpart")
print(Fit1)
print(Fit1$finalModel)
rattle::fancyRpartPlot(Fit1$finalModel)    # plot the classification tree
P1 <- predict(Fit1,newdata=testing)        # predict on testing subset
confusionMatrix(P1,testing$classe)         # Create a confusion matrix 

```
#Build Model - Random Forest
```{r,fig.width =8,fig.height = 8}
Fit2 <- randomForest(classe ~ .,data=training)
print(Fit2)
varImpPlot(Fit2,type=2)
P2 <- predict(Fit2,newdata=testing)
confusionMatrix(P2,testing$classe)

```
# Use Model built using randomForest algorithm, to predict the 20 different test cases
```{r}
ANS <- predict(Fit2,newdata=Trim_Test)
ANS
```

#For each test case, create a text file with a single capital letter (A, B, C, D, or E) corresponding to the above prediction for the corresponding problem in the test data set. 
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(ANS)

```
